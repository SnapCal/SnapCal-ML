{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.4.0\n",
    "%pip install tflite-support==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tflite-support\n",
      "Version: 0.3.1\n",
      "Summary: TFLite Support is a toolkit that helps users to develop ML and deploy TFLite models onto mobile devices.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google, LLC.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: d:\\bangkit\\tes\\kerasmodel\\.venv\\lib\\site-packages\n",
      "Requires: absl-py, flatbuffers, numpy, pybind11\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show tflite-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]\n",
      "TensorFlow version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "print(sys.version)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versi 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"ImageClassifier\",\n",
      "  \"description\": \"Identify the most prominent object in the image from a known set of categories.\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"image\",\n",
      "          \"description\": \"Input image to be classified.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"probability\",\n",
      "          \"description\": \"Probabilities of the labels respectively.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              0.0\n",
      "            ]\n",
      "          },\n",
      "          \"associated_files\": [\n",
      "            {\n",
      "              \"name\": \"labels.txt\",\n",
      "              \"description\": \"Labels for categories that the model can recognize.\",\n",
      "              \"type\": \"TENSOR_AXIS_LABELS\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tflite_support.metadata_writers import image_classifier\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "\n",
    "ImageClassifierWriter = image_classifier.MetadataWriter\n",
    "_MODEL_PATH = \"model.tflite\"\n",
    "# Task Library expects label files that are in the same format as the one below.\n",
    "_LABEL_FILE = \"labels.txt\"\n",
    "_SAVE_TO_PATH = \"model_metadata.tflite\"\n",
    "# Normalization parameters is required when reprocessing the image. It is\n",
    "# optional if the image pixel values are in range of [0, 255] and the input\n",
    "# tensor is quantized to uint8. See the introduction for normalization and\n",
    "# quantization parameters below for more details.\n",
    "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
    "_INPUT_NORM_MEAN = 127.5\n",
    "_INPUT_NORM_STD = 127.5\n",
    "\n",
    "# Create the metadata writer.\n",
    "writer = ImageClassifierWriter.create_for_inference(\n",
    "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
    "    [_LABEL_FILE])\n",
    "\n",
    "# Verify the metadata generated by metadata writer.\n",
    "print(writer.get_metadata_json())\n",
    "\n",
    "# Populate the metadata into the model.\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versi 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support.metadata_writers import image_classifier\n",
    "from tflite_support.metadata_writers import metadata_info\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "model_buffer = writer_utils.load_file(\"model.tflite\")\n",
    "\n",
    "# Create general model information.\n",
    "general_md = metadata_info.GeneralMd(\n",
    "    name=\"ImageClassifier\",\n",
    "    version=\"v1\",\n",
    "    description=(\"Identify foods in the image from a \"\n",
    "                 \"known set of categories.\"),\n",
    "    author=\"TensorFlow Lite\",\n",
    "    licenses=\"Apache License. Version 2.0\")\n",
    "\n",
    "# Create input tensor information.\n",
    "input_md = metadata_info.InputImageTensorMd(\n",
    "    name=\"input image\",\n",
    "    description=(\"Input image to be classified. The expected image is \"\n",
    "                 \"224 x 224, with three channels (red, blue, and green) per \"\n",
    "                 \"pixel. Each element in the tensor is a value between min and \"\n",
    "                 \"max, where (per-channel) min is [0] and max is [255].\"),\n",
    "    norm_mean=[127.5],\n",
    "    norm_std=[127.5],\n",
    "    color_space_type=_metadata_fb.ColorSpaceType.RGB,\n",
    "    tensor_type=writer_utils.get_input_tensor_types(model_buffer)[0])\n",
    "\n",
    "# Create output tensor information.\n",
    "output_md = metadata_info.ClassificationTensorMd(\n",
    "    name=\"probability\",\n",
    "    description=\"Probabilities of the 20 labels respectively.\",\n",
    "    label_files=[\n",
    "        metadata_info.LabelFileMd(file_path=\"labels.txt\",\n",
    "                                  locale=\"en\")\n",
    "    ],\n",
    "    tensor_type=writer_utils.get_output_tensor_types(model_buffer)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"ImageClassifier\",\n",
      "  \"description\": \"Identify foods in the image from a known set of categories.\",\n",
      "  \"version\": \"v1\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"input image\",\n",
      "          \"description\": \"Input image to be classified. The expected image is 224 x 224, with three channels (red, blue, and green) per pixel. Each element in the tensor is a value between min and max, where (per-channel) min is [0] and max is [255].\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"probability\",\n",
      "          \"description\": \"Probabilities of the 20 labels respectively.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              0.0\n",
      "            ]\n",
      "          },\n",
      "          \"associated_files\": [\n",
      "            {\n",
      "              \"name\": \"labels.txt\",\n",
      "              \"description\": \"Labels for categories that the model can recognize.\",\n",
      "              \"type\": \"TENSOR_AXIS_LABELS\",\n",
      "              \"locale\": \"en\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"author\": \"TensorFlow Lite\",\n",
      "  \"license\": \"Apache License. Version 2.0\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_SAVE_TO_PATH2 = \"model_metadata2.tflite\"\n",
    "\n",
    "ImageClassifierWriter = image_classifier.MetadataWriter\n",
    "# Create the metadata writer.\n",
    "writer = ImageClassifierWriter.create_from_metadata_info(\n",
    "    model_buffer, general_md, input_md, output_md)\n",
    "\n",
    "# Verify the metadata generated by metadata writer.\n",
    "print(writer.get_metadata_json())\n",
    "\n",
    "# Populate the metadata into the model.\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ujicoba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata populated:\n",
      "{\n",
      "  \"name\": \"ImageClassifier\",\n",
      "  \"description\": \"Identify foods in the image from a known set of categories.\",\n",
      "  \"version\": \"v1\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"input image\",\n",
      "          \"description\": \"Input image to be classified. The expected image is 224 x 224, with three channels (red, blue, and green) per pixel. Each element in the tensor is a value between min and max, where (per-channel) min is [0] and max is [255].\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"probability\",\n",
      "          \"description\": \"Probabilities of the 20 labels respectively.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              0.0\n",
      "            ]\n",
      "          },\n",
      "          \"associated_files\": [\n",
      "            {\n",
      "              \"name\": \"labels.txt\",\n",
      "              \"description\": \"Labels for categories that the model can recognize.\",\n",
      "              \"type\": \"TENSOR_AXIS_LABELS\",\n",
      "              \"locale\": \"en\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"author\": \"TensorFlow Lite\",\n",
      "  \"license\": \"Apache License. Version 2.0\",\n",
      "  \"min_parser_version\": \"1.0.0\"\n",
      "}\n",
      "\n",
      "Associated file(s) populated:\n",
      "file name:  labels.txt\n",
      "file content:\n",
      "b'ayam bakar\\nayam goreng\\nbakso\\nbubur ayam\\ngado\\ngulai kambing\\nlele goreng\\nnasi goreng\\nnasi putih\\nrawon\\nrendang\\nsambal goreng kentang\\nsate\\nseblak\\nsoto ayam\\ntahu goreng\\ntelur goreng\\ntempe goreng\\ntumis kangkung\\ntumis tauge'\n"
     ]
    }
   ],
   "source": [
    "from tflite_support import metadata\n",
    "\n",
    "displayer = metadata.MetadataDisplayer.with_model_file(\"model_metadata2.tflite\")\n",
    "print(\"Metadata populated:\")\n",
    "print(displayer.get_metadata_json())\n",
    "\n",
    "print(\"Associated file(s) populated:\")\n",
    "for file_name in displayer.get_packed_associated_file_list():\n",
    "  print(\"file name: \", file_name)\n",
    "  print(\"file content:\")\n",
    "  print(displayer.get_associated_file_buffer(file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
